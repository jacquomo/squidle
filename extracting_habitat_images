
## Extracting Representative Video Snippets in EventMeasure

# This script extracts video snippets for a representative (random) clip using data from EventMeasure software (https://www.seagis.com.au/event.html).
#
# Authors: jacquomo.monk@utas.edu.au, justin.hulls@utas.edu.au
#
# Prerequisites:
# - A folder containing all BRUV video files in a directory named "Converted".
# - A database export from EventMeasure with the following files in the working directory:
#   - "\Periods.txt"
#   - "\Metadata.csv" file structured according to GlobalArchive standards (see: https://marine-ecology.shinyapps.io/CheckEM/).
# - FFmpeg installed (https://www.ffmpeg.org/download.html).

# Clean up environment
rm(list=ls())

# Load required packages
library(tidyverse)
library(readxl)
library(lubridate)
library(sf)

## 1. Setup Working Directory
folder_path <- choose.dir() # Navigate to the working folder
setwd(folder_path)
getwd()

## 2. Define Metadata and Attributes
data.camera_model = "GoPro Hero10" #edit for your cameras
data.contact.primary ="neville.barrett@utas.edu.au" #add email for your primary contact person
data.contact.secondary = "jacquomo.monk@utas.edu.au" #add email for your secondary contact person	
data.funder = "Parks Australia"	#add funder names. If multiple delimit by semicolon
data.grant_no  = "DNP-MPA-2122-062" #(optional) add relevant grant numbers. If multiple delimit by semicolon

institute = "IMAS" #set this for your institute. should remain the same between uploads
platform = "IMAS_stereoROV" #set this for each platform format should remain the same between uploads 
campaign = "202408_Beagle_AMP" #set this for each campaign. format should remain the same between uploads
licence = "Creative Commons by Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)" #Set as appropriate 

## 3. Setup Folder Structure
base_dir <- file.path(campaign)
folders <- c("Highlight_Video", "MaxN_Video", "Representative_Video")
for (folder in folders) {
  dir_path <- file.path(base_dir, folder)
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
    message("Created folder: ", dir_path)
  } else {
    message("Folder already exists: ", dir_path)
  }
}

## 4. Load Marine Parks Shapefile (CAPAD for Australia)
mpa_url <- "https://gis.environment.gov.au/gispubmap/rest/services/ogc_services/CAPAD_Marine/MapServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json"
mpa <- st_read(mpa_url)
mpa <- st_make_valid(mpa)

## 5. Load Metadata File
meta <- read.csv(list.files(pattern = "*.csv")) %>%
  mutate(
    site = opcode,
    date_time = date_time,
    latitude = latitude_dd,
    longitude = longitude_dd,
    depth = depth_m, #needs to be a positive
    depth.zone = case_when(
      depth_m >= 0 & depth_m < 30 ~ "shallow",
      depth_m >= 30 & depth_m < 70 ~ "mesophotic",
      depth_m >= 70 & depth_m < 200 ~ "rariphotic",
      depth_m >= 200 & depth_m < 700 ~ "upper-slope",
      depth_m >= 700 & depth_m < 2000 ~ "mid-slope",
      depth_m >= 2000 & depth_m < 4000 ~ "lower-slope",
      depth_m >= 4000 & depth_m < 6000 ~ "abyss",
      depth_m >= 6000 ~ "hadal",
      TRUE ~ NA_character_
    ),
    camera_model = data.camera_model,
    contact.primary = data.contact.primary,
    contact.secondary = data.contact.secondary,
    licence = licence,
    funder = data.funder,
    grant.no = data.grant_no
  ) %>%
  select("site", "date_time", "latitude":"grant.no") %>%
  glimpse()

## 6. Perform Data Quality Checks
missing_values <- meta %>% summarise(across(everything(), ~ sum(is.na(.)))) %>% pivot_longer(everything(), names_to = "Column", values_to = "Missing_Count")
print("Missing values per column:")
print(missing_values)

duplicates <- meta %>%
  filter(duplicated(.))

if (nrow(duplicates) > 0) {
  print("Duplicate rows found:")
  print(duplicates)
} else {
  print("No duplicate rows found.")
}

## 7. Convert Metadata to Spatial Points and Assign MPAs
meta_sf <- st_as_sf(meta, coords = c("longitude", "latitude"), crs = 4326)
meta_mpa <- st_join(meta_sf, mpa, left = TRUE) %>%
  mutate(Name = replace_na(NAME, "Open"), IUCN = replace_na(IUCN, "Open")) %>%
  select(site, date_time, depth, depth.zone, camera_model, contact.primary, contact.secondary, licence, funder, grant.no, Name, IUCN) %>%
  rename(MPA.name = Name) %>%
  as.data.frame() %>%
  select(!c(geometry)) %>%
  glimpse()

## 8. Extract Frame Rates from Video Files
video_dir <- file.path(getwd(), "Converted")
video_files <- list.files(video_dir, pattern = "\\.(MP4|AVI)$", full.names = TRUE, ignore.case = TRUE)

get_video_fps <- function(video_path) {
  command <- paste("ffprobe -i", shQuote(video_path), "-show_entries stream=r_frame_rate -v quiet -of csv=\"p=0\"")
  fps <- system(command, intern = TRUE)
  fps_values <- as.numeric(unlist(strsplit(fps, "/")))
  fps_rate <- fps_values[1] / fps_values[2]
  return(fps_rate)
}

fps_table <- data.frame(Video = video_files, FPS = sapply(video_files, get_video_fps)) %>% mutate(Filename = basename(Video)) %>% glimpse()

## 9. Read EventMeasure Period File for Representative Events
# List files that contain "Period" and end with ".txt".
file_path <- list.files(pattern = "Period.*\\.txt$", full.names = TRUE) %>%
  enframe(name = NULL, value = "file_path") %>%
  pull(file_path)

# Check if any file was found and read it
if (length(file_path) > 0) {
  Periods <- read_delim(file_path, delim = "\t") 
  head(Periods)
} else {
  cat("No file with 'Period' in the name was found.")
}

## 10. Format start time to set extraction time point based on frame
Period.df <- Periods %>%#----
  dplyr::filter(PeriodIndex == 0)%>%#str_detect(Period, regex("bot", ignore_case = TRUE))) %>% # Filter based on bottom time #May need to change
  mutate(site = OpCode)%>%#str_extract(Filename, "\\b(?:\\d+_\\d+|EXP_\\d+)\\b")) %>%     # Extract 'Site' (matches patterns like "EXP_2" or "1_1")
  distinct(site, .keep_all = TRUE) %>%      # Have just one video per drop
  mutate(
    clip_start_in_seconds = (TimeStart*60)+180, # take a image @ 3mins into bottom time 
    # clip_start_in_seconds = (round(Time_in_seconds )),  # Start 10 seconds before MaxN
    clip_start_in_seconds = ifelse(clip_start_in_seconds < 0, 0, clip_start_in_seconds) # Prevent negative times
  ) %>%
  glimpse()

## 11. Join Period and video files to get the path
combined <- as.data.frame(video_files) %>%
  mutate(Filename = str_extract(video_files, "[^/]+$")) %>%
  mutate(site = str_extract(Filename, "(?<=_)[A-Z](_\\d+)(?=_)")) %>%  # Extracts "B_23"  # Extracts "B_23" or similar patterns. Edit as needed
  # mutate(site = str_extract(Filename, "(?<=_)(\\d+_\\d+)(?=_)")) %>%  # Extracts "1_1" pattern. Edit as needed
  right_join(meta_mpa, by = "site") %>%             # Right join to ensure all Video parts rows are kept
  dplyr::select(!Filename) %>%
  right_join(Period.df, by = "site")%>%
  glimpse()


## 12. Setup output folder and path for video clips 
#Ensure the output directory exists
output_dir <- paste(getwd(),campaign,"Representative_Video", sep= "/")
output_dir

if (!dir.exists(output_dir_rep)) {
  dir.create(output_dir_rep, recursive = TRUE)
}

## 13. Iterate over each row of 'combined' to process the video clips
for (i in 1:nrow(combined)) {
  
  # Get the video file path and name
  video_file <- combined$FilenameStart[i]
  video_full_path <- file.path(video_dir, video_file)  # Correct path construction
  
  # Check if the file exists (to avoid errors)
  if (!file.exists(video_full_path)) {
    cat("File not found:", video_full_path, "\n")
    next  # Skip to next iteration if file doesn't exist
  }
  
  # Get the start time for the clip
  clip_start_time <- combined$clip_start_in_seconds[i]
  
  # Generate the output video file name using the format: Filename_Comment_Time.mp4
  clean_video_file <- gsub("\\.[^.]+$", "", video_file)  # Remove video extension from the filename
  
  # Use Time to ensure a unique filename
  output_video_name <- paste0(clean_video_file, "_representative_", round(combined$TimeStart[i],2), ".MP4")
  output_video_path <- file.path(output_dir, output_video_name)
  
  # Create the FFmpeg command for video clip extraction
  ffmpeg_command <- paste0(
    "ffmpeg -i \"", normalizePath(video_full_path, winslash = "/"), "\"",  # Input video file
    " -ss ", clip_start_time,               # Start time for the clip
    " -an ",                              # Exclude audio
    " -t 30 ",                              # Duration of the clip (30 seconds)
    " -c:v libx264 -preset veryfast -crf 23 ",   # Compression settings cf ranges from 0-51 with lower better. 17-18 is visually lossless, but large file size. 19-23 good for most general uses
    " -profile:v high -level 4.2 ", #improves compatibility with web players
    " -movflags +faststart ", #places metadata at the beginning for faster playback
    "\"", normalizePath(output_video_path, winslash = "/"), "\""  # Output video file path
  )
  
  # Execute the FFmpeg command and capture the output
  cat("Running: ", ffmpeg_command, "\n")
  ffmpeg_output <- system(ffmpeg_command, intern = TRUE)
  
  # Print the ffmpeg output for debugging
  cat(ffmpeg_output, sep = "\n")
  
  # Check if the output file was created and has a valid size
  if (file.exists(output_video_path) && file.info(output_video_path)$size > 1024) {
    cat("Successfully created:", output_video_path, "\n")
  } else {
    cat("Failed to create a valid output file:", output_video_path, "\n")
  }
}

## 14. Format metadata and write out for highlight videos
# Get highlight video names and match back to metadata
rep_files <- list.files(output_dir, pattern = "\\.(MP4)$", full.names = TRUE, ignore.case = TRUE)

# Extract filenames without the path
rep_df <- data.frame(Filename.H = basename(rep_files), stringsAsFactors = FALSE)%>%
  mutate(site = str_extract(Filename.H, "(?<=_)[A-Z](_\\d+)(?=_)")) %>%  # Extracts "B_23"  # Extracts "B_23" or similar patterns. Edit as needed
  # mutate(site = str_extract(Filename, "(?<=_)(\\d+_\\d+)(?=_)")) %>%  # Extracts "1_1" pattern. Edit as needed
  glimpse()

# Combine with combined metadata df
final.meta<-combined%>%
  left_join(rep_df, by= "site")%>%
  dplyr::select(site:IUCN,Filename.H)%>%
  rename(filename=Filename.H)%>%
  mutate(institute=institute)%>%
  glimpse()

write.csv(final.meta, file = file.path(output_dir, paste0(campaign, "_", "Representative_Metadata.csv")), row.names = FALSE)
